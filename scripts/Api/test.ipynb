{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from apiFunc import init_pipeline, unfold_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kx/b3xc9jhj6qd_wgghcg01wqyr0000gn/T/ipykernel_52929/4173583897.py:1: DtypeWarning: Columns (27,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  init_df = pd.read_csv(\"../../data/partial/articles_partial_1.csv.zip\", compression=\"zip\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33650 entries, 0 to 33649\n",
      "Data columns (total 31 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Unnamed: 0                33650 non-null  int64  \n",
      " 1   id                        33650 non-null  object \n",
      " 2   type                      33650 non-null  object \n",
      " 3   sectionName               33650 non-null  object \n",
      " 4   webPublicationDate        33650 non-null  object \n",
      " 5   webTitle                  33650 non-null  object \n",
      " 6   isHosted                  33650 non-null  bool   \n",
      " 7   pillarName                33404 non-null  object \n",
      " 8   headline                  33650 non-null  object \n",
      " 9   trailText                 33649 non-null  object \n",
      " 10  byline                    32804 non-null  object \n",
      " 11  wordcount                 33650 non-null  int64  \n",
      " 12  firstPublicationDate      33646 non-null  object \n",
      " 13  lastModified              33650 non-null  object \n",
      " 14  liveBloggingNow           1167 non-null   object \n",
      " 15  productionOffice          33650 non-null  object \n",
      " 16  publication               33650 non-null  object \n",
      " 17  legallySensitive          33644 non-null  object \n",
      " 18  isLive                    33650 non-null  bool   \n",
      " 19  bodyText                  33135 non-null  object \n",
      " 20  commentCloseDate          7488 non-null   object \n",
      " 21  commentable               8297 non-null   object \n",
      " 22  newspaperPageNumber       16759 non-null  float64\n",
      " 23  newspaperEditionDate      17602 non-null  object \n",
      " 24  starRating                1512 non-null   float64\n",
      " 25  sensitive                 1308 non-null   object \n",
      " 26  displayHint               869 non-null    object \n",
      " 27  scheduledPublicationDate  10 non-null     object \n",
      " 28  contributorBio            12 non-null     object \n",
      " 29  tagWebTitle               33650 non-null  object \n",
      " 30  tagId                     33650 non-null  object \n",
      "dtypes: bool(2), float64(2), int64(2), object(25)\n",
      "memory usage: 7.5+ MB\n"
     ]
    }
   ],
   "source": [
    "init_df = pd.read_csv(\"../../data/partial/articles_partial_1.csv.zip\", compression=\"zip\")\n",
    "init_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33650 entries, 0 to 33649\n",
      "Data columns (total 31 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Unnamed: 0                33650 non-null  int64  \n",
      " 1   id                        33650 non-null  object \n",
      " 2   type                      33650 non-null  object \n",
      " 3   sectionName               33650 non-null  object \n",
      " 4   webPublicationDate        33650 non-null  object \n",
      " 5   webTitle                  33650 non-null  object \n",
      " 6   isHosted                  33650 non-null  bool   \n",
      " 7   pillarName                33404 non-null  object \n",
      " 8   headline                  33650 non-null  object \n",
      " 9   trailText                 33649 non-null  object \n",
      " 10  byline                    32804 non-null  object \n",
      " 11  wordcount                 33650 non-null  int64  \n",
      " 12  firstPublicationDate      33646 non-null  object \n",
      " 13  lastModified              33650 non-null  object \n",
      " 14  liveBloggingNow           1167 non-null   object \n",
      " 15  productionOffice          33650 non-null  object \n",
      " 16  publication               33650 non-null  object \n",
      " 17  legallySensitive          33644 non-null  object \n",
      " 18  isLive                    33650 non-null  bool   \n",
      " 19  bodyText                  33135 non-null  object \n",
      " 20  commentCloseDate          7488 non-null   object \n",
      " 21  commentable               8297 non-null   object \n",
      " 22  newspaperPageNumber       16759 non-null  float64\n",
      " 23  newspaperEditionDate      17602 non-null  object \n",
      " 24  starRating                1512 non-null   float64\n",
      " 25  sensitive                 1308 non-null   object \n",
      " 26  displayHint               869 non-null    object \n",
      " 27  scheduledPublicationDate  10 non-null     object \n",
      " 28  contributorBio            12 non-null     object \n",
      " 29  tagWebTitle               33650 non-null  object \n",
      " 30  tagId                     33650 non-null  object \n",
      "dtypes: bool(2), float64(2), int64(2), object(25)\n",
      "memory usage: 7.5+ MB\n"
     ]
    }
   ],
   "source": [
    "articles = (\n",
    "    init_df\n",
    "        #.pipe(init_pipeline)\n",
    ")\n",
    "articles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        The Pine Needles Lodge and Golf Club has alway...\n",
       "1        The Duke and Duchess of Cambridge have tweeted...\n",
       "2        “How was that not a penalty?” asks Ciaran Bren...\n",
       "3        The rain was hard enough to wake the sleeping ...\n",
       "4        An adviser to the mayor of Mariupol has said t...\n",
       "                               ...                        \n",
       "33645    China has opened an embassy in Nicaragua for t...\n",
       "33646    The year ahead will be dominated by efforts to...\n",
       "33647    Britain’s small businesses should expect trade...\n",
       "33648                                                  NaN\n",
       "33649    The Guardian’s racing correspondent, Greg Wood...\n",
       "Name: bodyText, Length: 33650, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.bodyText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/simo/Home/WBS-Bootcamp/the-guardian-analysis/scripts/Api/test.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/simo/Home/WBS-Bootcamp/the-guardian-analysis/scripts/Api/test.ipynb#ch0000004?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m pipeline\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/simo/Home/WBS-Bootcamp/the-guardian-analysis/scripts/Api/test.ipynb#ch0000004?line=1'>2</a>\u001b[0m classifier \u001b[39m=\u001b[39m pipeline(\u001b[39m\"\u001b[39;49m\u001b[39msentiment-analysis\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/simo/Home/WBS-Bootcamp/the-guardian-analysis/scripts/Api/test.ipynb#ch0000004?line=2'>3</a>\u001b[0m classifier(\u001b[39m\"\u001b[39m\u001b[39mI loved Star Wars so much!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/__init__.py:549\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/__init__.py?line=544'>545</a>\u001b[0m \u001b[39m# Infer the framework from the model\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/__init__.py?line=545'>546</a>\u001b[0m \u001b[39m# Forced if framework already defined, inferred if it's None\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/__init__.py?line=546'>547</a>\u001b[0m \u001b[39m# Will load the correct model if possible\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/__init__.py?line=547'>548</a>\u001b[0m model_classes \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[0;32m--> <a href='file:///opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/__init__.py?line=548'>549</a>\u001b[0m framework, model \u001b[39m=\u001b[39m infer_framework_load_model(\n\u001b[1;32m    <a href='file:///opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/__init__.py?line=549'>550</a>\u001b[0m     model,\n\u001b[1;32m    <a href='file:///opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/__init__.py?line=550'>551</a>\u001b[0m     model_classes\u001b[39m=\u001b[39;49mmodel_classes,\n\u001b[1;32m    <a href='file:///opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/__init__.py?line=551'>552</a>\u001b[0m     config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m    <a href='file:///opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/__init__.py?line=552'>553</a>\u001b[0m     framework\u001b[39m=\u001b[39;49mframework,\n\u001b[1;32m    <a href='file:///opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/__init__.py?line=553'>554</a>\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    <a href='file:///opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/__init__.py?line=554'>555</a>\u001b[0m     task\u001b[39m=\u001b[39;49mtask,\n\u001b[1;32m    <a href='file:///opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/__init__.py?line=555'>556</a>\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m    <a href='file:///opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/__init__.py?line=556'>557</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/__init__.py?line=558'>559</a>\u001b[0m model_config \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\n\u001b[1;32m    <a href='file:///opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/__init__.py?line=560'>561</a>\u001b[0m load_tokenizer \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(model_config) \u001b[39min\u001b[39;00m TOKENIZER_MAPPING \u001b[39mor\u001b[39;00m model_config\u001b[39m.\u001b[39mtokenizer_class \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py:198\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py?line=171'>172</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py?line=172'>173</a>\u001b[0m \u001b[39mSelect framework (TensorFlow or PyTorch) to use from the `model` passed. Returns a tuple (framework, model).\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py?line=173'>174</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py?line=194'>195</a>\u001b[0m \u001b[39m    `Tuple`: A tuple framework, model.\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py?line=195'>196</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py?line=196'>197</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_tf_available() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_available():\n\u001b[0;32m--> <a href='file:///opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py?line=197'>198</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py?line=198'>199</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAt least one of TensorFlow 2.0 or PyTorch should be installed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py?line=199'>200</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTo install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py?line=200'>201</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTo install PyTorch, read the instructions at https://pytorch.org/.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py?line=201'>202</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py?line=202'>203</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    <a href='file:///opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py?line=203'>204</a>\u001b[0m     model_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_from_pipeline\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m task\n",
      "\u001b[0;31mRuntimeError\u001b[0m: At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I loved Star Wars so much!\")\n",
    "##  [{'label': 'POSITIVE', 'score': 0.99}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.9.1-cp39-cp39-macosx_10_14_x86_64.whl (228.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.5/228.5 MB\u001b[0m \u001b[31m575.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:12\u001b[0m\n",
      "\u001b[?25hCollecting keras<2.10.0,>=2.9.0rc0\n",
      "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.46.3-cp39-cp39-macosx_10_10_x86_64.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.21.5)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.6.0)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.1.0-py3-none-any.whl (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.7/123.7 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m798.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers<2,>=1.12\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.12.1)\n",
      "Collecting tensorboard<2.10,>=2.9\n",
      "  Downloading tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m988.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
      "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m599.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.26.0-cp39-cp39-macosx_10_14_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.1-py2.py3-none-macosx_10_9_x86_64.whl (13.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m867.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (4.1.1)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (61.2.0)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.4-cp39-cp39-macosx_10_9_x86_64.whl (961 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.7/961.7 kB\u001b[0m \u001b[31m920.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.6.6-py2.py3-none-any.whl (156 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.7/156.7 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.27.1)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.0.3)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.8/97.8 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/anaconda3/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/anaconda3/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.11.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.5/151.5 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=e9ffe79eae6331faea1e486a9a5fbffb284ce8a15fd57373556a2dcbf53ec06d\n",
      "  Stored in directory: /Users/simo/Library/Caches/pip/wheels/b6/0d/90/0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
      "Successfully built termcolor\n",
      "Installing collected packages: termcolor, tensorboard-plugin-wit, libclang, keras, flatbuffers, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, protobuf, opt-einsum, oauthlib, keras-preprocessing, grpcio, google-pasta, gast, astunparse, absl-py, requests-oauthlib, markdown, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.1\n",
      "    Uninstalling protobuf-3.20.1:\n",
      "      Successfully uninstalled protobuf-3.20.1\n",
      "Successfully installed absl-py-1.1.0 astunparse-1.6.3 flatbuffers-1.12 gast-0.4.0 google-auth-2.6.6 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.46.3 keras-2.9.0 keras-preprocessing-1.1.2 libclang-14.0.1 markdown-3.3.7 oauthlib-3.2.0 opt-einsum-3.3.0 protobuf-3.19.4 requests-oauthlib-1.3.1 tensorboard-2.9.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0 tensorflow-io-gcs-filesystem-0.26.0 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
